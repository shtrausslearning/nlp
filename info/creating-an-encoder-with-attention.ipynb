{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e967b0bf",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-12-29T17:23:49.426605Z",
     "iopub.status.busy": "2022-12-29T17:23:49.425341Z",
     "iopub.status.idle": "2022-12-29T17:24:03.059912Z",
     "shell.execute_reply": "2022-12-29T17:24:03.058421Z"
    },
    "papermill": {
     "duration": 13.652779,
     "end_time": "2022-12-29T17:24:03.063009",
     "exception": false,
     "start_time": "2022-12-29T17:23:49.410230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertviz\r\n",
      "  Downloading bertviz-1.4.0-py3-none-any.whl (157 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.6/157.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.0 in /opt/conda/lib/python3.7/site-packages (from bertviz) (1.11.0+cpu)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from bertviz) (4.64.0)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from bertviz) (2021.11.10)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from bertviz) (0.1.97)\r\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from bertviz) (1.24.93)\r\n",
      "Requirement already satisfied: transformers>=2.0 in /opt/conda/lib/python3.7/site-packages (from bertviz) (4.20.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from bertviz) (2.28.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->bertviz) (4.4.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=2.0->bertviz) (21.3)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=2.0->bertviz) (0.12.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers>=2.0->bertviz) (4.13.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=2.0->bertviz) (1.21.6)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=2.0->bertviz) (3.7.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=2.0->bertviz) (0.10.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=2.0->bertviz) (6.0)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->bertviz) (1.0.1)\r\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.93 in /opt/conda/lib/python3.7/site-packages (from boto3->bertviz) (1.27.93)\r\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3->bertviz) (0.6.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->bertviz) (1.26.12)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->bertviz) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->bertviz) (2022.9.24)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->bertviz) (3.3)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.28.0,>=1.27.93->boto3->bertviz) (2.8.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers>=2.0->bertviz) (3.0.9)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers>=2.0->bertviz) (3.8.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.93->boto3->bertviz) (1.15.0)\r\n",
      "Installing collected packages: bertviz\r\n",
      "Successfully installed bertviz-1.4.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install bertviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb3e74f",
   "metadata": {
    "papermill": {
     "duration": 0.011097,
     "end_time": "2022-12-29T17:24:03.085866",
     "exception": false,
     "start_time": "2022-12-29T17:24:03.074769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b>1 <span style='color:#F1A424'>|</span> Transformer Encoder</b> \n",
    "\n",
    "***\n",
    "\n",
    "### <b><span style='color:#F1A424'>Background</span></b>\n",
    "\n",
    "First, some background to the notebook\n",
    "\n",
    "In the following notebook, we'll look at the following things\n",
    "\n",
    "<div style=\" background-color:#3b3745; padding: 13px 13px; border-radius: 8px; color: white\">\n",
    "    \n",
    "<ul>\n",
    "<li>Simple Attention</li>\n",
    "<li>Multi-Head Self Attention</li>\n",
    "<li>Feed Forward Layer</li>\n",
    "<li>Normalisation</li>\n",
    "<li>Skip Connection</li>\n",
    "<li>Position Embeddings</li>\n",
    "<li>Transformer Encoder</li>\n",
    "<li>Classifier Head</li>\n",
    "</ul> \n",
    "</div> \n",
    "\n",
    "### <b><span style='color:#F1A424'>Encoder Base</span></b>\n",
    "\n",
    "Encoder simply put:\n",
    "- Converts a **series tokens** into a **series of embedding vectors** (hidden state)\n",
    "- The encoder (neural network) consists of **multiple layers** (**blocks**) constructed together \n",
    "\n",
    "The encoder structure:\n",
    "- Composed of multiple encoder layers (blocks) stacked next to each other (similar to CNN layer stacks)\n",
    "- Each encoder block contains **multi-head self attention** & **fully connected feed forward layer** (for each input embedding)\n",
    "\n",
    "Purpose of the Encoder\n",
    "- Input tokens are encoded & modified into a form that **stores some contextual information** in the sequence\n",
    "\n",
    "The example we'll use:\n",
    "\n",
    "> the bark of a palm tree is very rough\n",
    "\n",
    "\n",
    "### <b><span style='color:#F1A424'>Classification Head</span></b>\n",
    "\n",
    "- Transformers can be utilised for various application so they are created in a base form\n",
    "- If we want to utilise them for a specific task, we add an extra component **head** to the transformer\n",
    "- In this example, we'll utilise it for **classification** purposes, and look at how we can combine the base with the **head**\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## <b>2 <span style='color:#F1A424'>|</span> Simple Self-Attention</b> \n",
    "\n",
    "***\n",
    "\n",
    "### <b><span style='color:#F1A424'>Types of Attention</span></b>\n",
    "\n",
    "**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention</mark>**\n",
    " \n",
    "- Mechanism which allows networks to assign **different weight distributions to each element** in a sequence \n",
    "- Elements in sequence - `token embeddings` (each token mapped to a vector of fixed dimension) (eg. BERT model - 768 dimensions)\n",
    " \n",
    " \n",
    "**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">self-attention</mark>**\n",
    "\n",
    "- Instead of using fixed embeddings for each token, can use whole sequence to **compute weighted average** of each `embedding`\n",
    "- One can think of self-attention as a form of averaging\n",
    "- Common form of `self-attention` **scaled dot-product attention** \n",
    "\n",
    "\n",
    "### <b><span style='color:#F1A424'>Four Main Steps</span></b>\n",
    "\n",
    "- Project each `token embedding` into three vectors **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">query</mark>**,**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">key</mark>**,**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">value</mark>**\n",
    "- Compute **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention scores</mark>** (nxn)\n",
    "\n",
    "    - (we determine how much the query & key vectors relate to eachother using a similarity function)\n",
    "    - Similarity function for scaled dot-product attention - dot product\n",
    "    - queries & keys that are similar will have large dot product & visa versa\n",
    "    - Outputs from this step - attention scores\n",
    "    \n",
    "    \n",
    "- Compute **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention weight</mark>** (wij)\n",
    "\n",
    "    - dot products produce large numbers \n",
    "    - attention scores first multiplied by a scaling factor to normalise their variance\n",
    "    - Then normalised with softmax to ensure all column values sum to 1\n",
    "    \n",
    "    \n",
    "- Update the token embeddings (hidden state)\n",
    "\n",
    "    - multiply the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">weights</mark>** by the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">value</mark>** vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b26728f",
   "metadata": {
    "papermill": {
     "duration": 0.012629,
     "end_time": "2022-12-29T17:24:03.109817",
     "exception": false,
     "start_time": "2022-12-29T17:24:03.097188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### <b><span style='color:#F1A424'>Step by Step : Simple Attention Formulation</span></b>\n",
    "\n",
    "- Well look at a simple example, and summarise the attention mechanism in one function\n",
    "- `bert-base-uncased` model will be used to extract different model settings (eg. number of attention heads), so we will be building a similar model \n",
    "\n",
    "<br>\n",
    "\n",
    "#### 1. Document tokenisation\n",
    "\n",
    "- Each token in the sentence has been mapped to a **unique identifier** from a **vocabulary** or **dictionary**\n",
    "- We start off by using the `bert-base-uncased` pretrained tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e928907f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:03.139665Z",
     "iopub.status.busy": "2022-12-29T17:24:03.139271Z",
     "iopub.status.idle": "2022-12-29T17:24:28.776406Z",
     "shell.execute_reply": "2022-12-29T17:24:28.774935Z"
    },
    "papermill": {
     "duration": 25.654154,
     "end_time": "2022-12-29T17:24:28.779313",
     "exception": false,
     "start_time": "2022-12-29T17:24:03.125159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faef8091a1344769ac2ece7d8b8364e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b747ee6cf5492aa13eb9441207764a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7f02ea87654128a7f7dd9196bd922b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfffb875dc344ceab0b976538bda564c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 433/433 [00:00<00:00, 200589.09B/s]\n",
      "100%|██████████| 440473133/440473133 [00:13<00:00, 33671532.37B/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from bertviz.transformers_neuron_view import BertModel\n",
    "\n",
    "# load tokeniser and model\n",
    "model_ckpt = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = BertModel.from_pretrained(model_ckpt)\n",
    "\n",
    "# document well be using as an exmaple\n",
    "text = \"the bark of a palm tree is very rough\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80978e7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:28.819616Z",
     "iopub.status.busy": "2022-12-29T17:24:28.819200Z",
     "iopub.status.idle": "2022-12-29T17:24:28.840166Z",
     "shell.execute_reply": "2022-12-29T17:24:28.838983Z"
    },
    "papermill": {
     "duration": 0.043622,
     "end_time": "2022-12-29T17:24:28.842546",
     "exception": false,
     "start_time": "2022-12-29T17:24:28.798924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1996, 11286,  1997,  1037,  5340,  3392,  2003,  2200,  5931]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenise input (text)\n",
    "inputs = tokenizer(text, \n",
    "                   return_tensors=\"pt\",      # pytorc tensor\n",
    "                   add_special_tokens=False) # don't use pad, sep tokens\n",
    "\n",
    "print(inputs.input_ids)\n",
    "inputs.input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4941bb22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:28.883023Z",
     "iopub.status.busy": "2022-12-29T17:24:28.882236Z",
     "iopub.status.idle": "2022-12-29T17:24:36.346388Z",
     "shell.execute_reply": "2022-12-29T17:24:36.345197Z"
    },
    "papermill": {
     "duration": 7.487384,
     "end_time": "2022-12-29T17:24:36.349003",
     "exception": false,
     "start_time": "2022-12-29T17:24:28.861619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the bark of a palm tree is very rough'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode sequence\n",
    "tokenizer.decode(inputs['input_ids'].tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a71404b",
   "metadata": {
    "papermill": {
     "duration": 0.02003,
     "end_time": "2022-12-29T17:24:36.388384",
     "exception": false,
     "start_time": "2022-12-29T17:24:36.368354",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "At this point:\n",
    "\n",
    "- `inputs.inpits_ids` A tensor of id mapped tokens\n",
    "- Token embeddings are **independent of their context**\n",
    "- **Homonyms** (same spelling, but different meaning) have the same representation\n",
    "\n",
    "Role of subsequent attention layers:\n",
    "\n",
    "- Mix the **token embeddings** to disambiguate & inform the representation of each token with the context of its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0382db6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:36.429781Z",
     "iopub.status.busy": "2022-12-29T17:24:36.429079Z",
     "iopub.status.idle": "2022-12-29T17:24:37.007941Z",
     "shell.execute_reply": "2022-12-29T17:24:37.006778Z"
    },
    "papermill": {
     "duration": 0.602565,
     "end_time": "2022-12-29T17:24:37.010561",
     "exception": false,
     "start_time": "2022-12-29T17:24:36.407996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 hidden size\n",
      "30522 vocabulary size\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Create an embedding layer\n",
    "\n",
    "'''\n",
    "\n",
    "from torch import nn\n",
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_ckpt)\n",
    "\n",
    "print(config.hidden_size,\"hidden size\")\n",
    "print(config.vocab_size,\"vocabulary size\")\n",
    "\n",
    "# load sample embedding layer of size (30522,758) -> same as bert-base\n",
    "token_emb = nn.Embedding(config.vocab_size,\n",
    "                         config.hidden_size)\n",
    "token_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779cfac8",
   "metadata": {
    "papermill": {
     "duration": 0.019274,
     "end_time": "2022-12-29T17:24:37.049684",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.030410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2. Embedding Vectors\n",
    "\n",
    "- Convert Tokenised data into embedding data (768 dimensions) using vocab of 30522 tokens\n",
    "- Each input_ids is **mapped to one of 30522 embedding vectors** stored in nn.embedding, each with a size of 768 \n",
    "- Our output will be [batch_size,seq_len,hidden_dim] by calling `nn.Embedding(hidden)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27eed320",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:37.091130Z",
     "iopub.status.busy": "2022-12-29T17:24:37.090127Z",
     "iopub.status.idle": "2022-12-29T17:24:37.104208Z",
     "shell.execute_reply": "2022-12-29T17:24:37.103222Z"
    },
    "papermill": {
     "duration": 0.037122,
     "end_time": "2022-12-29T17:24:37.106494",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.069372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Convert Tokens to Embedding Vectors\n",
    "utilising the existing model embedding embeddings\n",
    "\n",
    "'''\n",
    "\n",
    "inputs_embeds = token_emb(inputs.input_ids)\n",
    "inputs_embeds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb507626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:37.148875Z",
     "iopub.status.busy": "2022-12-29T17:24:37.148438Z",
     "iopub.status.idle": "2022-12-29T17:24:37.157903Z",
     "shell.execute_reply": "2022-12-29T17:24:37.156514Z"
    },
    "papermill": {
     "duration": 0.03338,
     "end_time": "2022-12-29T17:24:37.160530",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.127150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8709, -0.1843, -0.7062,  ...,  0.5614, -0.5979, -0.1744],\n",
       "         [-1.3574, -0.4618, -0.5609,  ...,  0.3766, -0.7757, -1.3060],\n",
       "         [ 0.2145, -0.8197,  0.4578,  ..., -0.5882,  1.3728,  0.0022],\n",
       "         ...,\n",
       "         [ 0.6875,  1.6081,  0.4598,  ..., -0.8235,  0.6205,  0.6845],\n",
       "         [ 1.1868,  0.0716,  0.2414,  ...,  0.6190, -0.3855,  0.7214],\n",
       "         [-0.8954,  1.0546, -0.2179,  ...,  0.0564,  0.3874, -0.4946]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9 embedding vectors of 768 dimensions\n",
    "inputs_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfc7a82",
   "metadata": {
    "papermill": {
     "duration": 0.020445,
     "end_time": "2022-12-29T17:24:37.200910",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.180465",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3. Create query, key and value vectors\n",
    "\n",
    "- As the most simplistic case of attention, **we set them equal to one another**\n",
    "- Attention mechanism with equal query and key vectors will assign a **very large score to identical words in the context** (diagonal component of matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a6e750b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:37.242974Z",
     "iopub.status.busy": "2022-12-29T17:24:37.242537Z",
     "iopub.status.idle": "2022-12-29T17:24:37.251822Z",
     "shell.execute_reply": "2022-12-29T17:24:37.250543Z"
    },
    "papermill": {
     "duration": 0.033278,
     "end_time": "2022-12-29T17:24:37.254112",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.220834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query and key components\n",
      "\n",
      "query size: torch.Size([1, 9, 768])\n",
      "key size: torch.Size([1, 768, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from math import sqrt\n",
    "\n",
    "# setting them equal to one another\n",
    "print(\"query and key components\\n\")\n",
    "query = key = value = inputs_embeds\n",
    "print('query size:',query.size())\n",
    "dim_k = key.size(-1)   # hidden dimension \n",
    "print('key size:',key.transpose(1,2).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fdb3b4",
   "metadata": {
    "papermill": {
     "duration": 0.019513,
     "end_time": "2022-12-29T17:24:37.294364",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.274851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 4. Compute the attention scores\n",
    "\n",
    "- Compute **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention scores</mark>** using the **dot product as the similarity function**\n",
    "- `torch.bmm` - batch matrix matrix product (as we work in batches during training)\n",
    "- If we need to transpose a vector `vector.transpose(1,2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eede5d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:37.336214Z",
     "iopub.status.busy": "2022-12-29T17:24:37.335503Z",
     "iopub.status.idle": "2022-12-29T17:24:37.352052Z",
     "shell.execute_reply": "2022-12-29T17:24:37.350732Z"
    },
    "papermill": {
     "duration": 0.040993,
     "end_time": "2022-12-29T17:24:37.354980",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.313987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dot product (attention scores)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dot product & apply normalisation\n",
    "print(\"\\ndot product (attention scores)\")\n",
    "scores = torch.bmm(query, key.transpose(1,2)) / sqrt(dim_k)\n",
    "scores.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1802a1a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:37.396886Z",
     "iopub.status.busy": "2022-12-29T17:24:37.396464Z",
     "iopub.status.idle": "2022-12-29T17:24:37.404534Z",
     "shell.execute_reply": "2022-12-29T17:24:37.403497Z"
    },
    "papermill": {
     "duration": 0.03155,
     "end_time": "2022-12-29T17:24:37.406662",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.375112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.8648e+01, -1.0776e+00,  2.9722e-01, -2.9451e-01, -2.1153e+00,\n",
       "          -2.0768e+00,  2.8204e-01,  8.9665e-01,  7.9191e-01],\n",
       "         [-1.0776e+00,  2.8015e+01, -7.0782e-01, -2.8204e-01,  8.8297e-01,\n",
       "          -3.5298e-01, -1.5330e+00, -1.3100e+00,  1.2302e-01],\n",
       "         [ 2.9722e-01, -7.0782e-01,  2.7576e+01, -1.6882e+00,  1.0794e+00,\n",
       "           6.6921e-01,  2.7391e-01,  1.0884e+00,  5.6002e-01],\n",
       "         [-2.9451e-01, -2.8204e-01, -1.6882e+00,  2.7700e+01,  1.5521e+00,\n",
       "           6.7132e-01, -1.7238e+00, -1.3852e-01, -7.7847e-01],\n",
       "         [-2.1153e+00,  8.8297e-01,  1.0794e+00,  1.5521e+00,  2.8228e+01,\n",
       "          -1.2328e-01,  8.3366e-01, -6.9877e-01, -5.7359e-01],\n",
       "         [-2.0768e+00, -3.5298e-01,  6.6921e-01,  6.7132e-01, -1.2328e-01,\n",
       "           2.6586e+01,  9.9523e-02,  9.9959e-03, -9.7113e-01],\n",
       "         [ 2.8204e-01, -1.5330e+00,  2.7391e-01, -1.7238e+00,  8.3366e-01,\n",
       "           9.9524e-02,  2.7679e+01,  4.2262e-01, -1.1332e-01],\n",
       "         [ 8.9665e-01, -1.3100e+00,  1.0884e+00, -1.3852e-01, -6.9877e-01,\n",
       "           9.9957e-03,  4.2262e-01,  2.7880e+01,  7.0499e-03],\n",
       "         [ 7.9191e-01,  1.2302e-01,  5.6001e-01, -7.7847e-01, -5.7359e-01,\n",
       "          -9.7113e-01, -1.1332e-01,  7.0499e-03,  2.5867e+01]]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aed073e",
   "metadata": {
    "papermill": {
     "duration": 0.019596,
     "end_time": "2022-12-29T17:24:37.446412",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.426816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 5. Compute attention weights (softmax function)\n",
    "\n",
    "- Created a 5x5 matrix of **attention scores** per sample in the batch\n",
    "- Apply the softmax for normalisation to get the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention weights</mark>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e34edd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:37.489105Z",
     "iopub.status.busy": "2022-12-29T17:24:37.488383Z",
     "iopub.status.idle": "2022-12-29T17:24:37.500825Z",
     "shell.execute_reply": "2022-12-29T17:24:37.499143Z"
    },
    "papermill": {
     "duration": 0.036654,
     "end_time": "2022-12-29T17:24:37.503350",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.466696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sotfmax applied, attention weights :\n",
      "\n",
      "torch.Size([1, 9, 9])\n",
      "tensor([[[1.0000e+00, 1.2309e-13, 4.8674e-13, 2.6935e-13, 4.3606e-14,\n",
      "          4.5319e-14, 4.7941e-13, 8.8640e-13, 7.9826e-13],\n",
      "         [2.3186e-13, 1.0000e+00, 3.3561e-13, 5.1375e-13, 1.6471e-12,\n",
      "          4.7856e-13, 1.4705e-13, 1.8379e-13, 7.7031e-13],\n",
      "         [1.4227e-12, 5.2076e-13, 1.0000e+00, 1.9537e-13, 3.1105e-12,\n",
      "          2.0638e-12, 1.3899e-12, 3.1385e-12, 1.8503e-12],\n",
      "         [6.9511e-13, 7.0384e-13, 1.7250e-13, 1.0000e+00, 4.4060e-12,\n",
      "          1.8260e-12, 1.6647e-13, 8.1246e-13, 4.2842e-13],\n",
      "         [6.6392e-14, 1.3312e-12, 1.6202e-12, 2.5994e-12, 1.0000e+00,\n",
      "          4.8669e-13, 1.2672e-12, 2.7373e-13, 3.1023e-13],\n",
      "         [3.5627e-13, 1.9972e-12, 5.5508e-12, 5.5625e-12, 2.5129e-12,\n",
      "          1.0000e+00, 3.1401e-12, 2.8712e-12, 1.0764e-12],\n",
      "         [1.2635e-12, 2.0574e-13, 1.2533e-12, 1.7001e-13, 2.1935e-12,\n",
      "          1.0527e-12, 1.0000e+00, 1.4542e-12, 8.5089e-13],\n",
      "         [1.9107e-12, 2.1031e-13, 2.3145e-12, 6.7861e-13, 3.8754e-13,\n",
      "          7.8727e-13, 1.1894e-12, 1.0000e+00, 7.8495e-13],\n",
      "         [1.2878e-11, 6.5973e-12, 1.0213e-11, 2.6783e-12, 3.2872e-12,\n",
      "          2.2089e-12, 5.2086e-12, 5.8749e-12, 1.0000e+00]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "sum of column values:/n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"sotfmax applied, attention weights :\\n\")\n",
    "weights = F.softmax(scores, dim=-1)\n",
    "print(weights.size())\n",
    "print(weights)\n",
    "\n",
    "print(\"\\nsum of column values:/n\")\n",
    "weights.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bf3e41",
   "metadata": {
    "papermill": {
     "duration": 0.020548,
     "end_time": "2022-12-29T17:24:37.544373",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.523825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 6. Update values \n",
    "\n",
    "Multiply the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention weights</mark>** matrix by the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">values</mark>** vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ee9930c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:37.586671Z",
     "iopub.status.busy": "2022-12-29T17:24:37.586282Z",
     "iopub.status.idle": "2022-12-29T17:24:37.596218Z",
     "shell.execute_reply": "2022-12-29T17:24:37.594611Z"
    },
    "papermill": {
     "duration": 0.034049,
     "end_time": "2022-12-29T17:24:37.598795",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.564746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8709, -0.1843, -0.7062,  ...,  0.5614, -0.5979, -0.1744],\n",
      "         [-1.3574, -0.4618, -0.5609,  ...,  0.3766, -0.7757, -1.3060],\n",
      "         [ 0.2145, -0.8197,  0.4578,  ..., -0.5882,  1.3728,  0.0022],\n",
      "         ...,\n",
      "         [ 0.6875,  1.6081,  0.4598,  ..., -0.8235,  0.6205,  0.6845],\n",
      "         [ 1.1868,  0.0716,  0.2414,  ...,  0.6190, -0.3855,  0.7214],\n",
      "         [-0.8954,  1.0546, -0.2179,  ...,  0.0564,  0.3874, -0.4946]]],\n",
      "       grad_fn=<BmmBackward0>)\n",
      "torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "attn_outputs = torch.bmm(weights, value)\n",
    "print(attn_outputs)\n",
    "print(attn_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caf792f",
   "metadata": {
    "papermill": {
     "duration": 0.020268,
     "end_time": "2022-12-29T17:24:37.639741",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.619473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we have a general function:\n",
    "- Which inputs vectors `query`, `key` & `value` \n",
    "- Calculates the scalar dot product attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdda6d2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:37.682848Z",
     "iopub.status.busy": "2022-12-29T17:24:37.681782Z",
     "iopub.status.idle": "2022-12-29T17:24:37.688509Z",
     "shell.execute_reply": "2022-12-29T17:24:37.687448Z"
    },
    "papermill": {
     "duration": 0.030417,
     "end_time": "2022-12-29T17:24:37.690798",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.660381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Scalar Dot Product Attention\n",
    "scores = query*key.T / sqrt(dims)\n",
    "weight = softmax(scores) \n",
    "\n",
    "'''\n",
    "\n",
    "def sdp_attention(query, key, value):\n",
    "    dim_k = query.size(-1) # dimension component\n",
    "    sfact = sqrt(dim_k)     \n",
    "    scores = torch.bmm(query, key.transpose(1,2)) / sfact\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    return torch.bmm(weights, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba9a63f",
   "metadata": {
    "papermill": {
     "duration": 0.021589,
     "end_time": "2022-12-29T17:24:37.732829",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.711240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b>3 <span style='color:#F1A424'>|</span> Multi-Head Self Attention</b> \n",
    "\n",
    "***\n",
    "\n",
    "- The meaning of the word will be better informed by **complementary words in the context** than by **identical words** (which gives 1)\n",
    "\n",
    "### <b><span style='color:#F1A424'>Simplistic Approach</span></b>\n",
    "\n",
    "- We only used the embeddings \"as is\" (no linear transformation) to compute the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention scores</mark>** **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention weights</mark>**\n",
    "\n",
    "### <b><span style='color:#F1A424'>Better Approach</span></b>\n",
    "\n",
    "- The **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">self-attention</mark>** layer applies **three independent linear transformations (`nn.linear`) to each embedding** to generate **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">query</mark>**,**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">key</mark>**,**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">value</mark>** \n",
    "- These transformations project the embeddings and **each projection carries its own set of learnable parameters** (**Weights**)\n",
    "- This **allows the self-attention layer to focus on different semantic aspects of the sequence**\n",
    "\n",
    "\n",
    "\n",
    "Its beneficial to have **multiple sets of linear projections** (each one represents an **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention head</mark>**)\n",
    "\n",
    "Why do we need more than one **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention head</mark>**?\n",
    "- The **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">softmax</mark>** of one head tends to focus on mostly **one aspect of similarity**\n",
    "\n",
    "\n",
    "**Several heads** allows the model to **focus on several apsects at once**\n",
    "- Eg. one head can focus on subject-verb interaction, another finds nearby adjectives\n",
    "- **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">CV analogy</mark>**: filters; one filter responsible for detecting the head, another for facial features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ed81009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:37.777008Z",
     "iopub.status.busy": "2022-12-29T17:24:37.776598Z",
     "iopub.status.idle": "2022-12-29T17:24:37.784283Z",
     "shell.execute_reply": "2022-12-29T17:24:37.783095Z"
    },
    "papermill": {
     "duration": 0.032795,
     "end_time": "2022-12-29T17:24:37.786401",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.753606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Attention Class\n",
    "\n",
    "# nn.linear : apply linear transformation to incoming data\n",
    "#             y = x * A^T + b\n",
    "# Ax = b where x is input, b is output, A is weight\n",
    "\n",
    "# calculate scaled dot product attention matrix\n",
    "# Requires embedding dimension \n",
    "# Each attention head is made of different q,k,v vectors\n",
    "\n",
    "'''\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \n",
    "    # initalisation \n",
    "    def __init__(self, embed_dim, head_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define the three vectors\n",
    "        # input - embed_dim, output - head_dim\n",
    "        self.q = nn.Linear(embed_dim, head_dim)\n",
    "        self.k = nn.Linear(embed_dim, head_dim)\n",
    "        self.v = nn.Linear(embed_dim, head_dim)\n",
    "\n",
    "    # main class operation\n",
    "    def forward(self, hidden_state):\n",
    "        \n",
    "        # calculate scaled dot product given a \n",
    "        attn_outputs = sdp_attention(\n",
    "            self.q(hidden_state), \n",
    "            self.k(hidden_state), \n",
    "            self.v(hidden_state))\n",
    "        \n",
    "        return attn_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff670d8",
   "metadata": {
    "papermill": {
     "duration": 0.02032,
     "end_time": "2022-12-29T17:24:37.827482",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.807162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`Attention` will be used in the construction of a model\n",
    "\n",
    "- We’ve **initialised three independent linear layers** that apply matrix multiplication to the embedding vectors to produce tensors of shape [batch_size, seq_len, head_dim]\n",
    "- Where head_dim is the number of dimensions we are projecting into\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "111a588d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:37.870323Z",
     "iopub.status.busy": "2022-12-29T17:24:37.869506Z",
     "iopub.status.idle": "2022-12-29T17:24:37.875739Z",
     "shell.execute_reply": "2022-12-29T17:24:37.874526Z"
    },
    "papermill": {
     "duration": 0.030104,
     "end_time": "2022-12-29T17:24:37.878027",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.847923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 heads\n",
      "768 hidden state embedding dimension\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "print(config.num_attention_heads,'heads')\n",
    "print(config.hidden_size,'hidden state embedding dimension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c4f2224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:37.920399Z",
     "iopub.status.busy": "2022-12-29T17:24:37.920006Z",
     "iopub.status.idle": "2022-12-29T17:24:37.928440Z",
     "shell.execute_reply": "2022-12-29T17:24:37.927403Z"
    },
    "papermill": {
     "duration": 0.032428,
     "end_time": "2022-12-29T17:24:37.930829",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.898401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention(\n",
       "  (q): Linear(in_features=768, out_features=12, bias=True)\n",
       "  (k): Linear(in_features=768, out_features=12, bias=True)\n",
       "  (v): Linear(in_features=768, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Sample Initialisation '''\n",
    "\n",
    "# Initialised just one head, requires token embedding vector for forward operation\n",
    "\n",
    "embed_dim = config.hidden_size\n",
    "num_heads = config.num_attention_heads\n",
    "\n",
    "attention = Attention(embed_dim,num_heads)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "346727db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:37.975715Z",
     "iopub.status.busy": "2022-12-29T17:24:37.974800Z",
     "iopub.status.idle": "2022-12-29T17:24:37.990827Z",
     "shell.execute_reply": "2022-12-29T17:24:37.989848Z"
    },
    "papermill": {
     "duration": 0.041521,
     "end_time": "2022-12-29T17:24:37.993098",
     "exception": false,
     "start_time": "2022-12-29T17:24:37.951577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1804, -0.0355,  0.2850, -0.0088,  0.0488,  0.0104, -0.1397,\n",
       "           0.1800, -0.1550,  0.1591, -0.3884, -0.3103],\n",
       "         [-0.2434, -0.0367,  0.2643, -0.1137, -0.0861,  0.0392, -0.1183,\n",
       "           0.1923, -0.1150,  0.0633, -0.3714, -0.2804],\n",
       "         [-0.2184, -0.0615,  0.2490,  0.0307,  0.0154,  0.0091, -0.1071,\n",
       "           0.1482, -0.1489,  0.1104, -0.3719, -0.2284],\n",
       "         [-0.2270,  0.0603,  0.2910, -0.1348, -0.0142,  0.0752, -0.1084,\n",
       "           0.2588, -0.0805,  0.1108, -0.4121, -0.2126],\n",
       "         [-0.2155,  0.0273,  0.2651, -0.0508,  0.0252,  0.0960, -0.0768,\n",
       "           0.2428, -0.0987,  0.0898, -0.3790, -0.0925],\n",
       "         [-0.2540, -0.0703,  0.2320, -0.0544, -0.0656,  0.0099, -0.1250,\n",
       "           0.1393, -0.1262,  0.0707, -0.3794, -0.2972],\n",
       "         [-0.2582, -0.0738,  0.2525, -0.0715, -0.0304,  0.1867, -0.0478,\n",
       "           0.1679, -0.1137, -0.0074, -0.3407, -0.0108],\n",
       "         [-0.2024,  0.0201,  0.2848, -0.0249,  0.0462,  0.1055, -0.0833,\n",
       "           0.2281, -0.1050,  0.1205, -0.3717, -0.0871],\n",
       "         [-0.2434, -0.0130,  0.2724, -0.0533, -0.0098,  0.1348, -0.0514,\n",
       "           0.2056, -0.1012,  0.0452, -0.3611, -0.0380]]],\n",
       "       grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights are always initialised randomly, attention_outputs varies\n",
    "attention_outputs = attention(inputs_embeds)\n",
    "attention_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06f2527c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:38.037569Z",
     "iopub.status.busy": "2022-12-29T17:24:38.037180Z",
     "iopub.status.idle": "2022-12-29T17:24:38.046076Z",
     "shell.execute_reply": "2022-12-29T17:24:38.044837Z"
    },
    "papermill": {
     "duration": 0.034713,
     "end_time": "2022-12-29T17:24:38.048747",
     "exception": false,
     "start_time": "2022-12-29T17:24:38.014034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Multihead attention class\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "class multiHeadAttention(nn.Module):\n",
    "    \n",
    "    # Config during initalisation\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        # model params, read from config file\n",
    "        embed_dim = config.hidden_size\n",
    "        num_heads = config.num_attention_heads\n",
    "        head_dim = embed_dim // num_heads\n",
    "        \n",
    "        # attention head (define only w/o hidden state)\n",
    "        # each attention head is initialised with embedd/heads head dimension\n",
    "        self.heads = nn.ModuleList(\n",
    "            [Attention(embed_dim, head_dim) for _ in range(num_heads)])\n",
    "        \n",
    "        # output uses whole embedding dimension for output\n",
    "        self.out_linear = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    # Given a hidden state (embeddings)\n",
    "    # Apply operation for multihead attention\n",
    "        \n",
    "    def forward(self, hidden_state):\n",
    "        \n",
    "        # for each head embed_size/heads, calculate attention\n",
    "        heads = [head(hidden_state) for head in self.heads] \n",
    "        x = torch.cat(heads, dim=-1) # merge/concat head data together\n",
    "    \n",
    "        # apply linear transformation to multihead attension scalar product\n",
    "        x = self.out_linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d220e81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:38.094108Z",
     "iopub.status.busy": "2022-12-29T17:24:38.093678Z",
     "iopub.status.idle": "2022-12-29T17:24:38.133088Z",
     "shell.execute_reply": "2022-12-29T17:24:38.132027Z"
    },
    "papermill": {
     "duration": 0.066429,
     "end_time": "2022-12-29T17:24:38.136808",
     "exception": false,
     "start_time": "2022-12-29T17:24:38.070379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1354,  0.0707, -0.0377,  ..., -0.0092,  0.0750, -0.1316],\n",
      "         [-0.1551,  0.0392, -0.0357,  ..., -0.0361,  0.1730, -0.1306],\n",
      "         [-0.1009, -0.0182, -0.0520,  ..., -0.0356,  0.0616, -0.1059],\n",
      "         ...,\n",
      "         [-0.1474,  0.0178, -0.1116,  ...,  0.0540,  0.0988, -0.1248],\n",
      "         [-0.2208,  0.0140, -0.0677,  ...,  0.0058,  0.0610, -0.0620],\n",
      "         [-0.1220,  0.0006, -0.0499,  ..., -0.0171,  0.0433, -0.0611]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Sample Usage: Multi-Head Attention\n",
    "\n",
    "'''\n",
    "\n",
    "# Every time will be different due to randomised weights\n",
    "multihead_attn = multiHeadAttention(config) # initialisation with config\n",
    "attn_output = multihead_attn(inputs_embeds) # forward by inputting embedding vectors (one for each token)\n",
    "\n",
    "# Attention output (attention weights matrix x vector weights concat)\n",
    "print(attn_output)\n",
    "print(attn_output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b4163b",
   "metadata": {
    "papermill": {
     "duration": 0.021085,
     "end_time": "2022-12-29T17:24:38.180338",
     "exception": false,
     "start_time": "2022-12-29T17:24:38.159253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b>4 <span style='color:#F1A424'>|</span> Feed-Forward Layer</b> \n",
    "\n",
    "***\n",
    "\n",
    "**position-wise feed-forward layer**\n",
    "\n",
    "The **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">feed-forward</mark>** sublayer in the encoder & decoder\n",
    "- **two layer fully connected neural network**\n",
    "\n",
    "\n",
    "However, instead of processing the whole sequence of embedding as a single vector, \n",
    "- it **processes each embedding** independently\n",
    "- Also see it referred to as a Conv1D with a kernel size of 1 (people with a CV background)\n",
    "\n",
    "\n",
    "The **hidden size** of the **1st layer = 4x size of the embeddings** & **GELU activation function**\n",
    "- Place where most of the capacity & memorization is hypothesized to happen\n",
    "- It is most often scaled, when scaling up the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "233ad12e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:38.224563Z",
     "iopub.status.busy": "2022-12-29T17:24:38.224141Z",
     "iopub.status.idle": "2022-12-29T17:24:38.232634Z",
     "shell.execute_reply": "2022-12-29T17:24:38.231435Z"
    },
    "papermill": {
     "duration": 0.033237,
     "end_time": "2022-12-29T17:24:38.235114",
     "exception": false,
     "start_time": "2022-12-29T17:24:38.201877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class feedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        self.linear2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    # define layer operations input x\n",
    "        \n",
    "    def forward(self, x):    # note must be forward\n",
    "        x = self.gelu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ae9bb06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:38.279257Z",
     "iopub.status.busy": "2022-12-29T17:24:38.278845Z",
     "iopub.status.idle": "2022-12-29T17:24:38.355426Z",
     "shell.execute_reply": "2022-12-29T17:24:38.354437Z"
    },
    "papermill": {
     "duration": 0.1014,
     "end_time": "2022-12-29T17:24:38.358041",
     "exception": false,
     "start_time": "2022-12-29T17:24:38.256641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feedForward(\n",
      "  (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (gelu): GELU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0497, -0.0443,  0.0052,  ...,  0.0450,  0.0032, -0.0255],\n",
       "         [ 0.0282, -0.0301, -0.0007,  ...,  0.0291, -0.0070, -0.0030],\n",
       "         [ 0.0378, -0.0340, -0.0034,  ...,  0.0357, -0.0095, -0.0130],\n",
       "         ...,\n",
       "         [ 0.0354, -0.0305,  0.0000,  ...,  0.0418, -0.0146, -0.0212],\n",
       "         [ 0.0332, -0.0255,  0.0119,  ...,  0.0454, -0.0115, -0.0250],\n",
       "         [ 0.0409, -0.0275, -0.0019,  ...,  0.0317, -0.0169, -0.0143]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initailise feedforward layer\n",
    "feed_forward = feedForward(config)              # initialise \n",
    "print(feed_forward,'\\n')\n",
    "\n",
    "# requires config & attn_outputs outputs\n",
    "ff_outputs = feed_forward(attn_output) # forward operation\n",
    "ff_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e557dd",
   "metadata": {
    "papermill": {
     "duration": 0.021335,
     "end_time": "2022-12-29T17:24:38.403015",
     "exception": false,
     "start_time": "2022-12-29T17:24:38.381680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b>5 <span style='color:#F1A424'>|</span> Normalisation Layers</b> \n",
    "\n",
    "***\n",
    "\n",
    "Transformer architecture also uses **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">layer normalisation</mark>** & **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">skip connections</mark>**\n",
    "- **normalisation** - normalises batch input to have zero mean & unit variance\n",
    "- **skip connections** - pass a tensor to the next level of the model w/o processing & adding it to the processed tensor\n",
    "\n",
    "Two main approaches, when it comes to normalisation layer placement in decoder, encoder:\n",
    "- **post layer** normalisation (transformer paper, layer normalisation b/w skip connections)\n",
    "- **pre layer** normalisation \n",
    "\n",
    "<br>\n",
    "\n",
    "| `post-layer` normalisation |  `pre-layer` normalisation in literature |\n",
    "| - | - |\n",
    "| Arrangement is tricky to train from scractch, as the gradients can diverge |  Most often found arrangement\n",
    "| Used with LR warm up (learning rate gradually increased, from small value to some maximum value during training) | Places layer normalization within the span of the skip connection |\n",
    "|  | Tends to be much more stable during training, and it does not usually require any learning rate warm-up |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acd46534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:38.447506Z",
     "iopub.status.busy": "2022-12-29T17:24:38.446700Z",
     "iopub.status.idle": "2022-12-29T17:24:38.454464Z",
     "shell.execute_reply": "2022-12-29T17:24:38.453151Z"
    },
    "papermill": {
     "duration": 0.032992,
     "end_time": "2022-12-29T17:24:38.457127",
     "exception": false,
     "start_time": "2022-12-29T17:24:38.424135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class encoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(config.hidden_size)\n",
    "        self.norm2 = nn.LayerNorm(config.hidden_size)\n",
    "        self.attention = multiHeadAttention(config)    # multihead attention layer \n",
    "        self.feed_forward = feedForward(config)        # feed forward layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Apply layer norm. to hidden state, copy input into query, key, value\n",
    "        # Apply attention with a skip connection\n",
    "        x = x + self.attention(self.norm1(x))\n",
    "        \n",
    "        # Apply feed-forward layer with a skip connection\n",
    "        x = x + self.feed_forward(self.norm2(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1186e73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:38.501785Z",
     "iopub.status.busy": "2022-12-29T17:24:38.501349Z",
     "iopub.status.idle": "2022-12-29T17:24:38.579620Z",
     "shell.execute_reply": "2022-12-29T17:24:38.578811Z"
    },
    "papermill": {
     "duration": 0.104716,
     "end_time": "2022-12-29T17:24:38.582940",
     "exception": false,
     "start_time": "2022-12-29T17:24:38.478224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoderLayer(\n",
      "  (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attention): multiHeadAttention(\n",
      "    (heads): ModuleList(\n",
      "      (0): Attention(\n",
      "        (q): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (k): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (v): Linear(in_features=768, out_features=64, bias=True)\n",
      "      )\n",
      "      (1): Attention(\n",
      "        (q): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (k): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (v): Linear(in_features=768, out_features=64, bias=True)\n",
      "      )\n",
      "      (2): Attention(\n",
      "        (q): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (k): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (v): Linear(in_features=768, out_features=64, bias=True)\n",
      "      )\n",
      "      (3): Attention(\n",
      "        (q): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (k): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (v): Linear(in_features=768, out_features=64, bias=True)\n",
      "      )\n",
      "      (4): Attention(\n",
      "        (q): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (k): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (v): Linear(in_features=768, out_features=64, bias=True)\n",
      "      )\n",
      "      (5): Attention(\n",
      "        (q): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (k): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (v): Linear(in_features=768, out_features=64, bias=True)\n",
      "      )\n",
      "      (6): Attention(\n",
      "        (q): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (k): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (v): Linear(in_features=768, out_features=64, bias=True)\n",
      "      )\n",
      "      (7): Attention(\n",
      "        (q): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (k): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (v): Linear(in_features=768, out_features=64, bias=True)\n",
      "      )\n",
      "      (8): Attention(\n",
      "        (q): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (k): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (v): Linear(in_features=768, out_features=64, bias=True)\n",
      "      )\n",
      "      (9): Attention(\n",
      "        (q): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (k): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (v): Linear(in_features=768, out_features=64, bias=True)\n",
      "      )\n",
      "      (10): Attention(\n",
      "        (q): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (k): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (v): Linear(in_features=768, out_features=64, bias=True)\n",
      "      )\n",
      "      (11): Attention(\n",
      "        (q): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (k): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (v): Linear(in_features=768, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (out_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (feed_forward): feedForward(\n",
      "    (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (gelu): GELU()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ") \n",
      "\n",
      "input torch.Size([1, 9, 768])\n",
      "output torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "# Transformer layer output\n",
    "encoder_layer = encoderLayer(config) # initialise encoder layer\n",
    "print(encoder_layer,'\\n')\n",
    "\n",
    "print('input',inputs_embeds.shape) \n",
    "print('output',encoder_layer(inputs_embeds).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99738112",
   "metadata": {
    "papermill": {
     "duration": 0.020997,
     "end_time": "2022-12-29T17:24:38.625390",
     "exception": false,
     "start_time": "2022-12-29T17:24:38.604393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There is an issue with the way we set up the **encoder layers** (which uses just embedding inputs)\n",
    "- they are totally **invariant to the position of the tokens**\n",
    "- Multi-head attention layer is effectively a weighted sum, the **information on token position is lost**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445ee0f6",
   "metadata": {
    "papermill": {
     "duration": 0.020752,
     "end_time": "2022-12-29T17:24:38.667355",
     "exception": false,
     "start_time": "2022-12-29T17:24:38.646603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## <b>6 <span style='color:#F1A424'>|</span> Positional Embeddings</b> \n",
    "\n",
    "***\n",
    "\n",
    "Let's incorporate positional information using **positional embeddings**\n",
    "\n",
    "\n",
    "**positional embeddings** are based on idea:\n",
    "  - Modify the **token embeddings** with a **position-dependent pattern** of values arranged in a vector\n",
    "  \n",
    "  \n",
    "If the pattern is characteristic for each position\n",
    "- the **attention heads** and **feed-forward layers** in each stack can learn to incorporate positional information into their transformations\n",
    "\n",
    "\n",
    "\n",
    "- There are several ways to achieve this, and one of the most popular approaches is to use a `learnable pattern`\n",
    "- This works exactly the same way as the token embeddings, but using the **position index** instead of the **token identifier** (from vocabulary dictionary) as input\n",
    "- An efficient way of encoding the positions of tokens is learned during pretraining\n",
    "\n",
    "Creating Custom `Embedding` class\n",
    "\n",
    "Let’s create a custom Embeddings module (**token embeddings + positional embeddings**)\n",
    " - That combines a token embedding layer that projects the input_ids to a dense hidden state \n",
    " - Together with the positional embedding that does the same for position_ids\n",
    " - The resulting embedding is simply the **sum of both embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef748244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:38.713100Z",
     "iopub.status.busy": "2022-12-29T17:24:38.712361Z",
     "iopub.status.idle": "2022-12-29T17:24:38.721730Z",
     "shell.execute_reply": "2022-12-29T17:24:38.720907Z"
    },
    "papermill": {
     "duration": 0.034685,
     "end_time": "2022-12-29T17:24:38.724181",
     "exception": false,
     "start_time": "2022-12-29T17:24:38.689496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Token + Position Embedding \n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "class tpEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):        \n",
    "        super().__init__()\n",
    "        \n",
    "        # token embedding layer\n",
    "        self.token_embeddings = nn.Embedding(config.vocab_size,\n",
    "                                             config.hidden_size)\n",
    "        \n",
    "        # positional embedding layer\n",
    "        # config.max_position_embeddings -> max number of positions in text 512 (tokens)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings,\n",
    "                                                config.hidden_size)\n",
    "        \n",
    "        self.norm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \n",
    "        # Create position IDs for input sequence\n",
    "        seq_length = input_ids.size(1) # number of tokens\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long)[None,:] # range(0,9)\n",
    "        \n",
    "        # tensor([[ 1996, 11286,  1997,  1037,  5340,  3392,  2003,  2200,  5931]])\n",
    "        # tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8]])\n",
    "        \n",
    "        # Create token and position embeddings\n",
    "        token_embeddings = self.token_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        \n",
    "        # Combine token and position embeddings\n",
    "        embeddings = token_embeddings + position_embeddings\n",
    "        \n",
    "        # Add normalisation & dropout layers\n",
    "        embeddings = self.norm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "130de5bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:38.768701Z",
     "iopub.status.busy": "2022-12-29T17:24:38.767925Z",
     "iopub.status.idle": "2022-12-29T17:24:39.027578Z",
     "shell.execute_reply": "2022-12-29T17:24:39.026362Z"
    },
    "papermill": {
     "duration": 0.285267,
     "end_time": "2022-12-29T17:24:39.030524",
     "exception": false,
     "start_time": "2022-12-29T17:24:38.745257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.9818, -0.0000,  0.0000,  ..., -0.3383, -0.0000, -2.5944],\n",
       "         [-5.0538, -0.0000, -2.1341,  ..., -0.0000,  0.0000, -1.2488],\n",
       "         [-0.0000,  0.0000,  1.4679,  ...,  0.0000, -0.0000, -3.0386],\n",
       "         ...,\n",
       "         [ 0.0000,  2.0134,  2.0548,  ..., -1.2429,  4.4909, -0.0000],\n",
       "         [-1.7996, -0.0000,  0.0000,  ..., -2.1656,  0.3933,  0.0000],\n",
       "         [ 0.0000, -1.9420, -0.0000,  ..., -0.0000, -0.0000, -0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Token and Position Embeddings\n",
    "embedding_layer = tpEmbedding(config)\n",
    "embedding_layer(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8757cb",
   "metadata": {
    "papermill": {
     "duration": 0.021017,
     "end_time": "2022-12-29T17:24:39.074844",
     "exception": false,
     "start_time": "2022-12-29T17:24:39.053827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b>7 <span style='color:#F1A424'>|</span> Putting it all Together</b> \n",
    "\n",
    "***\n",
    "\n",
    "- Constructing the Transformer **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">encoder</mark>**, combining the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">Embedding</mark>** and **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">Encoder</mark>**  layers\n",
    "- We utilise both **token** & **positional** embeddings using `tpEmbedding`\n",
    "- For a given number of heads, we store `encoderLayer`, which contains the **attention** & **feed-forward** layers (which are our layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6a32d04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:39.119593Z",
     "iopub.status.busy": "2022-12-29T17:24:39.118951Z",
     "iopub.status.idle": "2022-12-29T17:24:39.126707Z",
     "shell.execute_reply": "2022-12-29T17:24:39.125665Z"
    },
    "papermill": {
     "duration": 0.033069,
     "end_time": "2022-12-29T17:24:39.129106",
     "exception": false,
     "start_time": "2022-12-29T17:24:39.096037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full transformer encoder combining the `Embedding` with the ``Embedding` ` layers\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):       \n",
    "        super().__init__()\n",
    "        \n",
    "        # token & positional embedding layer\n",
    "        self.embeddings = tpEmbedding(config)\n",
    "        \n",
    "        # attention & forward feed layer \n",
    "        self.layers = nn.ModuleList([encoderLayer(config)\n",
    "                                     for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # embeddings layer output\n",
    "        x = self.embeddings(x)\n",
    "        \n",
    "        # cycle through all heads\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df78eb69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:39.175173Z",
     "iopub.status.busy": "2022-12-29T17:24:39.174794Z",
     "iopub.status.idle": "2022-12-29T17:24:40.439136Z",
     "shell.execute_reply": "2022-12-29T17:24:40.437773Z"
    },
    "papermill": {
     "duration": 1.290387,
     "end_time": "2022-12-29T17:24:40.441766",
     "exception": false,
     "start_time": "2022-12-29T17:24:39.151379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3150, -0.9448, -1.9527,  ...,  0.4258, -0.5694, -3.3036],\n",
       "         [-0.9168, -0.6489,  0.9373,  ...,  0.6969,  1.5973, -0.5345],\n",
       "         [ 1.0490, -1.5161,  1.6764,  ...,  1.0162, -2.1198,  2.6263],\n",
       "         ...,\n",
       "         [-0.5821, -5.6414, -2.3057,  ...,  1.1826, -1.0920, -2.5330],\n",
       "         [-1.6120, -1.7331,  0.7028,  ...,  1.3954,  2.4647,  0.9209],\n",
       "         [ 1.0205,  1.4829, -0.8654,  ..., -1.8677, -3.3867,  1.6848]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoder initialisation & output\n",
    "encoder = TransformerEncoder(config)\n",
    "encoder_output = encoder(inputs.input_ids)\n",
    "encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fc45926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:40.489571Z",
     "iopub.status.busy": "2022-12-29T17:24:40.489137Z",
     "iopub.status.idle": "2022-12-29T17:24:40.495717Z",
     "shell.execute_reply": "2022-12-29T17:24:40.494584Z"
    },
    "papermill": {
     "duration": 0.032914,
     "end_time": "2022-12-29T17:24:40.498114",
     "exception": false,
     "start_time": "2022-12-29T17:24:40.465200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hidden state for each token in a batch\n",
    "encoder_output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331d0893",
   "metadata": {
    "papermill": {
     "duration": 0.02139,
     "end_time": "2022-12-29T17:24:40.541224",
     "exception": false,
     "start_time": "2022-12-29T17:24:40.519834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b>8 <span style='color:#F1A424'>|</span> Classification Head</b> \n",
    "\n",
    "***\n",
    "\n",
    "Quite often, transformers are divided into:\n",
    "- Task independent body (`TransformerEncoder`)\n",
    "- Task dependent head (`TransformerClassifier`)\n",
    "\n",
    "Select one of the token outputs:\n",
    "- The first token in such models is often used for the prediction **[CLS] token**\n",
    "- Can attach a `dropout` and a `linear` transformation layer to make a classification prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bceef246",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:40.587029Z",
     "iopub.status.busy": "2022-12-29T17:24:40.586633Z",
     "iopub.status.idle": "2022-12-29T17:24:40.593378Z",
     "shell.execute_reply": "2022-12-29T17:24:40.592561Z"
    },
    "papermill": {
     "duration": 0.032239,
     "end_time": "2022-12-29T17:24:40.595775",
     "exception": false,
     "start_time": "2022-12-29T17:24:40.563536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        self.encoder = TransformerEncoder(config)\n",
    "        \n",
    "        # Classification Head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)[:, 0, :] # select hidden state of [CLS] token\n",
    "        print(x.size())\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier(x) # 768 -> 3 \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ff01b3",
   "metadata": {
    "papermill": {
     "duration": 0.021266,
     "end_time": "2022-12-29T17:24:40.639111",
     "exception": false,
     "start_time": "2022-12-29T17:24:40.617845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- For each sample in the batch we get the **unnormalized logits** for each class in the output, which corresponds to the BERT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b54ed43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T17:24:40.684532Z",
     "iopub.status.busy": "2022-12-29T17:24:40.683346Z",
     "iopub.status.idle": "2022-12-29T17:24:42.155555Z",
     "shell.execute_reply": "2022-12-29T17:24:42.154362Z"
    },
    "papermill": {
     "duration": 1.498253,
     "end_time": "2022-12-29T17:24:42.158857",
     "exception": false,
     "start_time": "2022-12-29T17:24:40.660604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0015, 0.8205, 0.6130]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.num_labels = 3\n",
    "encoder_classifier = TransformerClassifier(config)\n",
    "output = encoder_classifier(inputs.input_ids)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 64.224446,
   "end_time": "2022-12-29T17:24:45.048311",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-29T17:23:40.823865",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00acdb928a40403cb6aebb25c04d1584": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7020d4db132546f8821dc34f05ada5ae",
       "placeholder": "​",
       "style": "IPY_MODEL_145b358bb5d34052afbdcf5cd8ae094e",
       "value": "Downloading: 100%"
      }
     },
     "145b358bb5d34052afbdcf5cd8ae094e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "187bdb71604648a898c4a581ec0b702e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_55f01fecf29f47b98f760e373e985270",
       "max": 570.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_eafda45b5cc3456c93a3d9ee0b8eab54",
       "value": 570.0
      }
     },
     "21e13b3ce69a433baccf7e3d756c419d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2a7f02ea87654128a7f7dd9196bd922b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e01c37fb19b043efa6ae084673b6d97b",
        "IPY_MODEL_7f2ee964d83749e18f52102d60b2ea54",
        "IPY_MODEL_7143c35afb024a56a83077ed7abc99d4"
       ],
       "layout": "IPY_MODEL_4fbe9b53f37b408f9f9d2e2089a77b63"
      }
     },
     "2a859b3181884e6597bc833b651f0b58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8777f2d5e5d84f1594c637ca49a8a43d",
       "placeholder": "​",
       "style": "IPY_MODEL_f3b1bedd08bf4b218869b64aacddc779",
       "value": " 28.0/28.0 [00:00&lt;00:00, 868B/s]"
      }
     },
     "3fd61831f8944f759919ad88e744c5bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "423465c1241d460cacf2c8350649bb50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "439493fd01d04293b13c34c837a0908b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "44e388ed47ee4328b10d64b79d78e956": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a87a8595fa194671b5460d41344a44ef",
       "placeholder": "​",
       "style": "IPY_MODEL_beffa9609dcc4b2696e454d3a3bf1727",
       "value": " 455k/455k [00:00&lt;00:00, 1.22MB/s]"
      }
     },
     "45e623070a724c64add07563dabb17dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49d5f087f2124fc38b422c86c07b5de4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4fbe9b53f37b408f9f9d2e2089a77b63": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "53c55d3e44784a97a0a3e2ad859818e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5439bd9db6a44639a88dc3f87d49970a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "55f01fecf29f47b98f760e373e985270": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "578e46a042314eaf85516d03cf3a3525": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5df3b00a4d784dc583b0d8bdd4335852": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6472b990ad1949f5a7b0dc55d8029e38": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6dd03da08e9d4162ab0bebf1b325aee8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7020d4db132546f8821dc34f05ada5ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7143c35afb024a56a83077ed7abc99d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5439bd9db6a44639a88dc3f87d49970a",
       "placeholder": "​",
       "style": "IPY_MODEL_87ae82ddef204a1da2013dcada87a922",
       "value": " 226k/226k [00:00&lt;00:00, 937kB/s]"
      }
     },
     "757417b74cfa428c9a4cd5d6a8ead23a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_49d5f087f2124fc38b422c86c07b5de4",
       "placeholder": "​",
       "style": "IPY_MODEL_578e46a042314eaf85516d03cf3a3525",
       "value": "Downloading: 100%"
      }
     },
     "7b969d071edc45a8ad1b408dcfbd66c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f2ee964d83749e18f52102d60b2ea54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d2d125f0ddbc4b82bbd454b900de4dd0",
       "max": 231508.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_439493fd01d04293b13c34c837a0908b",
       "value": 231508.0
      }
     },
     "84b747ee6cf5492aa13eb9441207764a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_00acdb928a40403cb6aebb25c04d1584",
        "IPY_MODEL_187bdb71604648a898c4a581ec0b702e",
        "IPY_MODEL_c5cb6a180edb4156a3e5ff940753ebed"
       ],
       "layout": "IPY_MODEL_423465c1241d460cacf2c8350649bb50"
      }
     },
     "8777f2d5e5d84f1594c637ca49a8a43d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "87ae82ddef204a1da2013dcada87a922": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8893131c513a449a989cadcc5851500f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6dd03da08e9d4162ab0bebf1b325aee8",
       "placeholder": "​",
       "style": "IPY_MODEL_53c55d3e44784a97a0a3e2ad859818e4",
       "value": "Downloading: 100%"
      }
     },
     "93b930b479aa444c81cb2d9429031083": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a82da975ebef488d8248942725e579d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c18fec0f5ddf4f76a4b0b41f5dcf8270",
       "max": 28.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_21e13b3ce69a433baccf7e3d756c419d",
       "value": 28.0
      }
     },
     "a87a8595fa194671b5460d41344a44ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af2f4fdcd58c448b9e83e544de364dcc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "beffa9609dcc4b2696e454d3a3bf1727": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c18fec0f5ddf4f76a4b0b41f5dcf8270": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c5cb6a180edb4156a3e5ff940753ebed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7b969d071edc45a8ad1b408dcfbd66c3",
       "placeholder": "​",
       "style": "IPY_MODEL_e18d048d391a4f9d94552e2b2880eece",
       "value": " 570/570 [00:00&lt;00:00, 19.8kB/s]"
      }
     },
     "cf8f41182b414e5f82c45f6bbfddfa6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_93b930b479aa444c81cb2d9429031083",
       "max": 466062.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3fd61831f8944f759919ad88e744c5bd",
       "value": 466062.0
      }
     },
     "d2d125f0ddbc4b82bbd454b900de4dd0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dfffb875dc344ceab0b976538bda564c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8893131c513a449a989cadcc5851500f",
        "IPY_MODEL_cf8f41182b414e5f82c45f6bbfddfa6b",
        "IPY_MODEL_44e388ed47ee4328b10d64b79d78e956"
       ],
       "layout": "IPY_MODEL_6472b990ad1949f5a7b0dc55d8029e38"
      }
     },
     "e01c37fb19b043efa6ae084673b6d97b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_af2f4fdcd58c448b9e83e544de364dcc",
       "placeholder": "​",
       "style": "IPY_MODEL_5df3b00a4d784dc583b0d8bdd4335852",
       "value": "Downloading: 100%"
      }
     },
     "e18d048d391a4f9d94552e2b2880eece": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "eafda45b5cc3456c93a3d9ee0b8eab54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f3b1bedd08bf4b218869b64aacddc779": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "faef8091a1344769ac2ece7d8b8364e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_757417b74cfa428c9a4cd5d6a8ead23a",
        "IPY_MODEL_a82da975ebef488d8248942725e579d5",
        "IPY_MODEL_2a859b3181884e6597bc833b651f0b58"
       ],
       "layout": "IPY_MODEL_45e623070a724c64add07563dabb17dc"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
