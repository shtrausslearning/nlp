{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-07-18T23:09:36.958800Z","iopub.status.busy":"2023-07-18T23:09:36.958287Z","iopub.status.idle":"2023-07-18T23:09:49.284002Z","shell.execute_reply":"2023-07-18T23:09:49.282817Z","shell.execute_reply.started":"2023-07-18T23:09:36.958762Z"},"id":"pcTANDU1RaW6","outputId":"f6d3edb0-2521-42b1-b021-2ce8dec3f295","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.31.0)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.13.1)\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.21.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"]}],"source":["! pip install transformers datasets accelerate -U"]},{"cell_type":"markdown","metadata":{"id":"XB5cwyyzRaXU"},"source":["# **Masked language modeling**\n","\n","- Masked language modeling predicts a masked token in a sequence, and the model can attend to tokens bidirectionally. \n","- This means the model has full access to the tokens on the left and right. \n","- Masked language modeling is great for tasks that require a good contextual understanding of an entire sequence.\n","- BERT is an example of a masked language model.\n","\n","This guide will show you how to:\n","\n","- Finetune DistilRoBERTa on the r/askscience subset of the ELI5 dataset\n","- Use your finetuned model for inference\n"]},{"cell_type":"markdown","metadata":{"id":"mWc8SJqyRaXb"},"source":["## **Load ELI5 dataset**\n","\n","The **[ELI5 dataset](https://huggingface.co/datasets/eli5)** is an English-language dataset of questions and answers gathered from three subreddits \n","- where users ask factual questions requiring paragraph-length or longer answers\n","\n","The dataset was created to support the task of open-domain long form abstractive question answering\n","- covers questions about general topics in its r/explainlikeimfive subset, science in it r/askscience subset, and History in its r/AskHistorians subset"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-07-18T23:10:34.019667Z","iopub.status.busy":"2023-07-18T23:10:34.019222Z","iopub.status.idle":"2023-07-18T23:11:23.350095Z","shell.execute_reply":"2023-07-18T23:11:23.349073Z","shell.execute_reply.started":"2023-07-18T23:10:34.019635Z"},"id":"c2zTS9bpRaXc","outputId":"5f4fc333-ba3f-41c5-9b98-026bf2e16d11","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e1dec21da41456cbf9cfbee09b98b94","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/18.2k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"180b80f085d449f49867537e309618f9","version_major":2,"version_minor":0},"text/plain":["Downloading metadata:   0%|          | 0.00/6.36k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3d6a91e17b34c86a47b19d3db306fd1","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/15.8k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset eli5/LFQA_reddit to /root/.cache/huggingface/datasets/eli5/LFQA_reddit/1.0.0/17574e5502a10f41bbd17beba83e22475b499fa62caa1384a3d093fc856fe6fa...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca7edb272ead4ccbb18f5ca18ca612fd","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/3.50k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe75b054619649f598183c368540aa0f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/576M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"984c28b4e2274ffca147a6d7aeb811b8","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/21.1M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"afe78efd644944c6ae4fdd386dda3564","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/53.0M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dbb8fc6509364d3f94cdcc6da71c3888","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/286M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4868425f22264a66a7061b4e908aa605","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/9.65M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"99b2ac816d0d46d7be53b97763309532","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0eeeb87f270f4912a24f30301f82f638","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/330M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d9198106f824f2ca99e6ab4dd21afd8","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/18.7M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"469b3adddca74ac98a0aba15b2b5bcd7","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/36.2M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset eli5 downloaded and prepared to /root/.cache/huggingface/datasets/eli5/LFQA_reddit/1.0.0/17574e5502a10f41bbd17beba83e22475b499fa62caa1384a3d093fc856fe6fa. Subsequent calls will reuse this data.\n"]},{"data":{"text/plain":["['q_id',\n"," 'title',\n"," 'selftext',\n"," 'document',\n"," 'subreddit',\n"," 'answers',\n"," 'title_urls',\n"," 'selftext_urls',\n"," 'answers_urls']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["from datasets import load_dataset\n","import warnings; warnings.filterwarnings('ignore')\n","\n","eli5 = load_dataset(\"eli5\", split=\"train_asks[:5000]\")\n","eli5.column_names"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-07-18T23:11:47.038788Z","iopub.status.busy":"2023-07-18T23:11:47.038194Z","iopub.status.idle":"2023-07-18T23:11:47.084393Z","shell.execute_reply":"2023-07-18T23:11:47.083499Z","shell.execute_reply.started":"2023-07-18T23:11:47.038748Z"},"id":"z5NqW7RvRaXe","outputId":"bd982141-a37c-4736-ac01-a1cbe985096b","trusted":true},"outputs":[{"data":{"text/plain":["{'q_id': '1dpyfn',\n"," 'title': 'Is it possible for their to be light of a frequency that would disrupt nuclear bonding?',\n"," 'selftext': 'Ultraviolet light can break down ionic bonds (or was it covalent?). Is it possible that a light of the correct frequency could break down the bonds holding the nucleus of an atom together?',\n"," 'document': '',\n"," 'subreddit': 'askscience',\n"," 'answers': {'a_id': ['c9spkh6', 'c9sp02d'],\n","  'text': [\"Theoretically, yes. The nucleus is a bound state, hit it with the right bundle of energy (a photon), and you can excite the weakest bound nucleon off of the atom. It's easiest to think of deuterium: It's an electron, a proton, and a neutron. Knock off the electron with something low energy (an ultraviolet photon, only 15.5 eV). This leaves you with a bound proton-neutron system. Theoretically, you can then zap it with another photon of the proton neutron binding energy (2.22 MeV). The binding energy of the deuterium nucleus is thus greater than the energy output of most lasers (it's firmly in the gamma ray spectrum, which is expected, because nuclear transitions make gamma rays). So, in most cases, you'll find that to complete disintegrate your nucleus, you're going to need to do some careful thinking. Deuterium is the simplest non-trivial nucleus, and already we'd need a second radioactive source producing the necessary x-rays. But, again, in theory, yes, light can break up nuclei.\",\n","   \"Sounds like you're looking for _URL_0_, unless there's some subtlety that I'm missing\"],\n","  'score': [6, 2]},\n"," 'title_urls': {'url': []},\n"," 'selftext_urls': {'url': []},\n"," 'answers_urls': {'url': ['http://en.wikipedia.org/wiki/Photodisintegration']}}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["eli5 = eli5.train_test_split(test_size=0.2)\n","eli5[\"train\"][0]"]},{"cell_type":"markdown","metadata":{"id":"JJjPePGwRaXi"},"source":["While this may look like a lot, you're only really interested in the `text` field. What's cool about language modeling tasks is you don't need labels (also known as an unsupervised task) because the next word *is* the label."]},{"cell_type":"markdown","metadata":{"id":"RLBHmWY2RaXl"},"source":["## **Preprocess**\n","\n","For masked language modeling, the next step is to load a DistilRoBERTa tokenizer to process the `text` subfield:"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T23:11:49.496252Z","iopub.status.busy":"2023-07-18T23:11:49.495863Z","iopub.status.idle":"2023-07-18T23:11:52.783790Z","shell.execute_reply":"2023-07-18T23:11:52.782758Z","shell.execute_reply.started":"2023-07-18T23:11:49.496221Z"},"id":"OpZqnrHTRaXu","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0dbcc28c2f914b68991e8c9efdd20c04","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a402477a79e04a019029fca3dc3cef6b","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de7e660fe17b4a1f9fe44fffe56714ff","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a3356593aa74570b395d01b5ff2ded2","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")"]},{"cell_type":"markdown","metadata":{"id":"t9qeCxyuRaXv"},"source":["- You'll notice from the example above, the `text` field is actually nested inside `answers`.\n","- This means you'll need to extract the `text` subfield from its nested structure with the [`flatten`](https://huggingface.co/docs/datasets/process.html#flatten) method:"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-07-18T23:12:02.546924Z","iopub.status.busy":"2023-07-18T23:12:02.546176Z","iopub.status.idle":"2023-07-18T23:12:02.566827Z","shell.execute_reply":"2023-07-18T23:12:02.565613Z","shell.execute_reply.started":"2023-07-18T23:12:02.546888Z"},"id":"nrWAc7P3RaXw","outputId":"c084d7a7-a457-4663-c5c5-6abe436aa247","trusted":true},"outputs":[{"data":{"text/plain":["[\"Theoretically, yes. The nucleus is a bound state, hit it with the right bundle of energy (a photon), and you can excite the weakest bound nucleon off of the atom. It's easiest to think of deuterium: It's an electron, a proton, and a neutron. Knock off the electron with something low energy (an ultraviolet photon, only 15.5 eV). This leaves you with a bound proton-neutron system. Theoretically, you can then zap it with another photon of the proton neutron binding energy (2.22 MeV). The binding energy of the deuterium nucleus is thus greater than the energy output of most lasers (it's firmly in the gamma ray spectrum, which is expected, because nuclear transitions make gamma rays). So, in most cases, you'll find that to complete disintegrate your nucleus, you're going to need to do some careful thinking. Deuterium is the simplest non-trivial nucleus, and already we'd need a second radioactive source producing the necessary x-rays. But, again, in theory, yes, light can break up nuclei.\",\n"," \"Sounds like you're looking for _URL_0_, unless there's some subtlety that I'm missing\"]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["eli5 = eli5.flatten()\n","eli5[\"train\"][0]['answers.text']"]},{"cell_type":"markdown","metadata":{"id":"59rmNHRMRaX0"},"source":["- Each subfield is now a separate column as indicated by the `answers` prefix, and the `text` field is a list now\n","- Instead of tokenizing each sentence separately, convert the list to a string so you can jointly tokenize them\n","- To apply this preprocessing function over the entire dataset\n","- You can speed up the `map` function by setting `batched=True` to process multiple elements of the dataset at once, and increasing the number of processes with `num_proc`"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173,"referenced_widgets":["df68c92063af4ff59421b9caaaef5855","351363cab27a41e881b0b74bf2d1999c","229719041b724dbe97fcfe084b9043ee","869cc8b998a845b489eb68fe6e88ac50","47393e92ea524d2a827cdb9472a7171d","ba81b2b950d34ef48d76fa8b0882f593","8b41d9f7c8bb44b5814c4902a55c8a63","02bfefd23d464472bda7e3491696b430","31345129733f4fb7a4d0224ce2459f9e","9ec762e2334640558d7f63d61f15d908","17fe8038501c4a39b537ba68806f5633","c4ff946a030e40ae85c1d8cd56688e00","96cc49fa3ad942699d4c60d269017ea6","934693e68d7d4fd29321807791cc1219","8f2a40c472d3478b89425e31aba2ad50","05382371c1024c8394a0380b3d6dfdba","a5db6afbe5af48069650cb86ec449712","f93e3d599f8b4edeb796b64068569e8b","d510c91c0f814f4cb2eea064fbecd039","e2eeb063c2e94339a8b8ca6ce7bf67d4","cd405ff754d043c5bd262585aa90bd15","7a25f92d77f64e1294a22936832c7afd"]},"execution":{"iopub.execute_input":"2023-07-18T23:12:05.275050Z","iopub.status.busy":"2023-07-18T23:12:05.274356Z","iopub.status.idle":"2023-07-18T23:12:09.890239Z","shell.execute_reply":"2023-07-18T23:12:09.889182Z","shell.execute_reply.started":"2023-07-18T23:12:05.275006Z"},"id":"9xi0DXDzRaX1","outputId":"fc94212a-59f3-43d0-f33e-6a15fd16436a","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/4000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1478 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (895 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (2062 > 512). Running this sequence through the model will result in indexing errors\n"]}],"source":["# join the list of strings for each example and tokenise the result\n","def preprocess_function(examples):\n","    return tokenizer([\" \".join(x) for x in examples[\"answers.text\"]])\n","\n","tokenized_eli5 = eli5.map(\n","    preprocess_function,\n","    batched=True,\n","    num_proc=4,\n","    remove_columns=eli5[\"train\"].column_names, # remove columns we don't need\n",")"]},{"cell_type":"markdown","metadata":{"id":"9SKjSajDRaX2"},"source":["This dataset contains the token sequences, but some of these are longer than the maximum input length for the model.\n","\n","You can now use a second preprocessing function to\n","- concatenate all the sequences\n","- split the concatenated sequences into shorter chunks defined by `block_size`, which should be both shorter than the maximum input length and short enough for your GPU RAM."]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T23:12:23.632331Z","iopub.status.busy":"2023-07-18T23:12:23.631924Z","iopub.status.idle":"2023-07-18T23:12:23.641647Z","shell.execute_reply":"2023-07-18T23:12:23.640203Z","shell.execute_reply.started":"2023-07-18T23:12:23.632291Z"},"id":"PdEMyxNxRaX3","trusted":true},"outputs":[],"source":["block_size = 128\n","def group_texts(examples):\n","    # Concatenate all texts.\n","    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n","    total_length = len(concatenated_examples[list(examples.keys())[0]])\n","    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n","    # customize this part to your needs.\n","    if total_length >= block_size:\n","        total_length = (total_length // block_size) * block_size\n","    # Split by chunks of block_size.\n","    result = {\n","        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n","        for k, t in concatenated_examples.items()\n","    }\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","    return result"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["0473f936ad7946c081eb5eb3c960ac50","dd0fceec185e4599b47ae23faee3035d","6cc5fe03d90442b7ae9ddef68718294a","24b640cd355c473a8fe2030c20a0e668","a9d74f1019a54c27b73f921c4830baed","c2276432c3084b72b910ebf741f99d11","f21e83cb77bf4aa7865d73cc1b3473f3","21a35285aac948f59d6e36580a8c1b8d","84ac6b3b66fe4e98a7630cba84d15043","cb7571e81c3342cdbe6fed2d92af893a","18f01d2111a845dbbc3367f67dd717ed","aa15cf00c1b845488acbde30273c5ccb","191989a159b84e488e24a9d2e2d2a2f2","9956a4d0c09f4c1ab3bdac9cb65fcf9b","0875575b709f414f9958fb57d970d0c7","48c2dce0e41349e59785ad194ba2e15c","f0061ccdc9234fcda904d781685c52c9","cd2a3614cccb4b0d80c4245f6994d684","5e86f2a59beb483fb776c96ee779fccd","c124773d5fb548228754d1f6453b6e2a","9dc8f682dc3f4405bdd9aee7f40206c0","7c2523448e644b8abd511e143742314e"]},"execution":{"iopub.execute_input":"2023-07-18T23:12:32.816202Z","iopub.status.busy":"2023-07-18T23:12:32.815842Z","iopub.status.idle":"2023-07-18T23:12:39.275183Z","shell.execute_reply":"2023-07-18T23:12:39.273953Z","shell.execute_reply.started":"2023-07-18T23:12:32.816171Z"},"id":"4ZAwCpfnRaX6","outputId":"24bf2ea3-41fd-4ccb-ba5e-3b008e74d992","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/4000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Apply the `group_texts` function over the entire dataset\n","lm_dataset = tokenized_eli5.map(group_texts,\n","                                batched=True,\n","                                num_proc=4)"]},{"cell_type":"markdown","metadata":{"id":"3VOswg9NRaX7"},"source":["Now create a batch of examples using DataCollatorForLanguageModeling\n","- It's more efficient to *dynamically pad* the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length.\n","- Use the EOS token as the padding token, specify `mlm_probability` to randomly mask tokens each time you iterate over the data:"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T23:13:00.853160Z","iopub.status.busy":"2023-07-18T23:13:00.852781Z","iopub.status.idle":"2023-07-18T23:13:11.474562Z","shell.execute_reply":"2023-07-18T23:13:11.473518Z","shell.execute_reply.started":"2023-07-18T23:13:00.853128Z"},"id":"R1b4Ue25RaX8","trusted":true},"outputs":[],"source":["from transformers import DataCollatorForLanguageModeling\n","\n","tokenizer.pad_token = tokenizer.eos_token\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,\n","                                                mlm_probability=0.15)"]},{"cell_type":"markdown","metadata":{"id":"mOJa1iW_RaX9"},"source":["## **Fine Tune Model**\n","\n","Load DistilRoBERTa with AutoModelForMaskedLM"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-07-18T23:13:20.593546Z","iopub.status.busy":"2023-07-18T23:13:20.592711Z","iopub.status.idle":"2023-07-18T23:13:27.807257Z","shell.execute_reply":"2023-07-18T23:13:27.806254Z","shell.execute_reply.started":"2023-07-18T23:13:20.593509Z"},"id":"BgY0BEGxRaX_","outputId":"30b4c1ff-5b52-453d-d467-a506d9b39fef","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e8cc34bdfd29497bb8f43636cfcdb459","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["from transformers import AutoModelForMaskedLM\n","\n","model = AutoModelForMaskedLM.from_pretrained(\"distilroberta-base\")"]},{"cell_type":"markdown","metadata":{"id":"zdDKxZ4JRaYC"},"source":["At this point, only three steps remain:\n","\n","- Define your training hyperparameters in TrainingArguments.\n","- The only required parameter is `output_dir` which specifies where to save your model\n","- Pass the training arguments to Trainer along with the model, datasets, and data collator\n","- Call train() to finetune your model."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"execution":{"iopub.execute_input":"2023-07-18T23:13:47.095013Z","iopub.status.busy":"2023-07-18T23:13:47.094614Z","iopub.status.idle":"2023-07-18T23:20:28.981829Z","shell.execute_reply":"2023-07-18T23:20:28.980696Z","shell.execute_reply.started":"2023-07-18T23:13:47.094980Z"},"id":"GjBhYx3XRaYI","outputId":"b124da31-c1e5-40da-802f-ae24c2d2c327","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3375' max='3375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3375/3375 06:34, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.251100</td>\n","      <td>2.065639</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.164500</td>\n","      <td>2.017307</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>2.116800</td>\n","      <td>1.984272</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=3375, training_loss=2.1876857096354168, metrics={'train_runtime': 396.1183, 'train_samples_per_second': 68.116, 'train_steps_per_second': 8.52, 'total_flos': 894600396366336.0, 'train_loss': 2.1876857096354168, 'epoch': 3.0})"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import TrainingArguments, Trainer\n","import os\n","os.environ['WANDB_DISABLED'] = 'true'\n","\n","training_args = TrainingArguments(\n","    output_dir=\"my_awesome_eli5_mlm_model\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    save_strategy = \"no\",\n","    save_total_limit = 2,\n","    load_best_model_at_end=False\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=lm_dataset[\"train\"],\n","    eval_dataset=lm_dataset[\"test\"],\n","    data_collator=data_collator,\n",")\n","\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"cWly2MpIRaYL"},"source":["Once training is completed, use the evaluate method to evaluate your model and get its perplexity"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T23:20:28.984332Z","iopub.status.busy":"2023-07-18T23:20:28.983863Z","iopub.status.idle":"2023-07-18T23:20:39.348284Z","shell.execute_reply":"2023-07-18T23:20:39.347317Z","shell.execute_reply.started":"2023-07-18T23:20:28.984293Z"},"id":"-hKFrRZeRaYQ","trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='295' max='295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [295/295 00:10]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Perplexity: 7.14\n"]}],"source":["import math\n","eval_results = trainer.evaluate()\n","print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T23:20:39.349883Z","iopub.status.busy":"2023-07-18T23:20:39.349524Z","iopub.status.idle":"2023-07-18T23:20:40.028347Z","shell.execute_reply":"2023-07-18T23:20:40.027349Z","shell.execute_reply.started":"2023-07-18T23:20:39.349847Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('my_awesome_eli5_mlm_model/tokenizer_config.json',\n"," 'my_awesome_eli5_mlm_model/special_tokens_map.json',\n"," 'my_awesome_eli5_mlm_model/vocab.json',\n"," 'my_awesome_eli5_mlm_model/merges.txt',\n"," 'my_awesome_eli5_mlm_model/added_tokens.json',\n"," 'my_awesome_eli5_mlm_model/tokenizer.json')"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# save model and tokeniser\n","trainer.save_model(\"my_awesome_eli5_mlm_model\")\n","tokenizer.save_pretrained(\"my_awesome_eli5_mlm_model\")"]},{"cell_type":"markdown","metadata":{"id":"VX3qF9BGRaYV"},"source":["## **Inference**\n","\n","- Great, now that you've finetuned a model, you can use it for inference!\n","- Come up with some text you'd like the model to fill in the blank with, and use the special `<mask>` token to indicate the blank"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T23:23:37.569455Z","iopub.status.busy":"2023-07-18T23:23:37.568952Z","iopub.status.idle":"2023-07-18T23:23:46.406688Z","shell.execute_reply":"2023-07-18T23:23:46.405622Z","shell.execute_reply.started":"2023-07-18T23:23:37.569411Z"},"id":"cZlqwtFZRaYY","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"266fca7501cf43f594461e73ed5a3cec","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0534ff00048b44e0a96016e5aac8d1d7","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/329M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["The Milky Way is a  spiral galaxy.\n","The Milky Way is a  massive galaxy.\n","The Milky Way is a  small galaxy.\n"]}],"source":["from transformers import AutoTokenizer\n","from transformers import AutoModelForMaskedLM\n","import torch\n","\n","text = \"The Milky Way is a <mask> galaxy.\"\n","\n","# Tokenize the text and return the `input_ids` as PyTorch tensors. \n","# You'll also need to specify the position of the `<mask>` token:\n","tokenizer = AutoTokenizer.from_pretrained(\"my_awesome_eli5_mlm_model\")\n","inputs = tokenizer(text, return_tensors=\"pt\")\n","mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n","\n","# Pass your inputs to the model and return the `logits` of the masked token\n","model = AutoModelForMaskedLM.from_pretrained(\"stevhliu/my_awesome_eli5_mlm_model\")\n","logits = model(**inputs).logits\n","mask_token_logits = logits[0, mask_token_index, :]\n","\n","# Then return the three masked tokens with the highest probability and print them out\n","top_3_tokens = torch.topk(mask_token_logits, 3, dim=1).indices[0].tolist()\n","\n","for token in top_3_tokens:\n","    print(text.replace(tokenizer.mask_token, tokenizer.decode([token])))"]},{"cell_type":"markdown","metadata":{},"source":["## **Pipeline**\n","\n","- The simplest way to try out your finetuned model for inference is to use it in a pipeline()\n","- Instantiate a `pipeline` for fill-mask with your model, and pass your text to it\n","- If you like, you can use the `top_k` parameter to specify how many predictions to return"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T23:24:54.776843Z","iopub.status.busy":"2023-07-18T23:24:54.776438Z","iopub.status.idle":"2023-07-18T23:24:58.074659Z","shell.execute_reply":"2023-07-18T23:24:58.062376Z","shell.execute_reply.started":"2023-07-18T23:24:54.776812Z"},"id":"BSQszPKERaYc","trusted":true},"outputs":[{"data":{"text/plain":["[{'score': 0.37157338857650757,\n","  'token': 21300,\n","  'token_str': ' spiral',\n","  'sequence': 'The Milky Way is a spiral galaxy.'},\n"," {'score': 0.11231834441423416,\n","  'token': 2232,\n","  'token_str': ' massive',\n","  'sequence': 'The Milky Way is a massive galaxy.'},\n"," {'score': 0.06813511252403259,\n","  'token': 30794,\n","  'token_str': ' dwarf',\n","  'sequence': 'The Milky Way is a dwarf galaxy.'}]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import pipeline\n","\n","mask_filler = pipeline(\"fill-mask\", \"my_awesome_eli5_mlm_model\")\n","mask_filler(text, top_k=3)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"02bfefd23d464472bda7e3491696b430":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0473f936ad7946c081eb5eb3c960ac50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd0fceec185e4599b47ae23faee3035d","IPY_MODEL_6cc5fe03d90442b7ae9ddef68718294a","IPY_MODEL_24b640cd355c473a8fe2030c20a0e668"],"layout":"IPY_MODEL_a9d74f1019a54c27b73f921c4830baed"}},"05382371c1024c8394a0380b3d6dfdba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"0875575b709f414f9958fb57d970d0c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9dc8f682dc3f4405bdd9aee7f40206c0","placeholder":"​","style":"IPY_MODEL_7c2523448e644b8abd511e143742314e","value":" 750/1000 [00:01&lt;00:00, 567.24 examples/s]"}},"17fe8038501c4a39b537ba68806f5633":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18f01d2111a845dbbc3367f67dd717ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"191989a159b84e488e24a9d2e2d2a2f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0061ccdc9234fcda904d781685c52c9","placeholder":"​","style":"IPY_MODEL_cd2a3614cccb4b0d80c4245f6994d684","value":"Map (num_proc=4):  75%"}},"21a35285aac948f59d6e36580a8c1b8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"229719041b724dbe97fcfe084b9043ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_02bfefd23d464472bda7e3491696b430","max":4000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31345129733f4fb7a4d0224ce2459f9e","value":4000}},"24b640cd355c473a8fe2030c20a0e668":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb7571e81c3342cdbe6fed2d92af893a","placeholder":"​","style":"IPY_MODEL_18f01d2111a845dbbc3367f67dd717ed","value":" 4000/4000 [00:09&lt;00:00, 705.73 examples/s]"}},"31345129733f4fb7a4d0224ce2459f9e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"351363cab27a41e881b0b74bf2d1999c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba81b2b950d34ef48d76fa8b0882f593","placeholder":"​","style":"IPY_MODEL_8b41d9f7c8bb44b5814c4902a55c8a63","value":"Map (num_proc=4): 100%"}},"47393e92ea524d2a827cdb9472a7171d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"48c2dce0e41349e59785ad194ba2e15c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"5e86f2a59beb483fb776c96ee779fccd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cc5fe03d90442b7ae9ddef68718294a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_21a35285aac948f59d6e36580a8c1b8d","max":4000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84ac6b3b66fe4e98a7630cba84d15043","value":4000}},"7a25f92d77f64e1294a22936832c7afd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c2523448e644b8abd511e143742314e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84ac6b3b66fe4e98a7630cba84d15043":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"869cc8b998a845b489eb68fe6e88ac50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ec762e2334640558d7f63d61f15d908","placeholder":"​","style":"IPY_MODEL_17fe8038501c4a39b537ba68806f5633","value":" 4000/4000 [00:07&lt;00:00, 807.16 examples/s]"}},"8b41d9f7c8bb44b5814c4902a55c8a63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f2a40c472d3478b89425e31aba2ad50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd405ff754d043c5bd262585aa90bd15","placeholder":"​","style":"IPY_MODEL_7a25f92d77f64e1294a22936832c7afd","value":" 1000/1000 [00:01&lt;00:00, 770.72 examples/s]"}},"934693e68d7d4fd29321807791cc1219":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d510c91c0f814f4cb2eea064fbecd039","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2eeb063c2e94339a8b8ca6ce7bf67d4","value":1000}},"96cc49fa3ad942699d4c60d269017ea6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5db6afbe5af48069650cb86ec449712","placeholder":"​","style":"IPY_MODEL_f93e3d599f8b4edeb796b64068569e8b","value":"Map (num_proc=4): 100%"}},"9956a4d0c09f4c1ab3bdac9cb65fcf9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e86f2a59beb483fb776c96ee779fccd","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c124773d5fb548228754d1f6453b6e2a","value":1000}},"9dc8f682dc3f4405bdd9aee7f40206c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ec762e2334640558d7f63d61f15d908":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5db6afbe5af48069650cb86ec449712":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9d74f1019a54c27b73f921c4830baed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"aa15cf00c1b845488acbde30273c5ccb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_191989a159b84e488e24a9d2e2d2a2f2","IPY_MODEL_9956a4d0c09f4c1ab3bdac9cb65fcf9b","IPY_MODEL_0875575b709f414f9958fb57d970d0c7"],"layout":"IPY_MODEL_48c2dce0e41349e59785ad194ba2e15c"}},"ba81b2b950d34ef48d76fa8b0882f593":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c124773d5fb548228754d1f6453b6e2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2276432c3084b72b910ebf741f99d11":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4ff946a030e40ae85c1d8cd56688e00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_96cc49fa3ad942699d4c60d269017ea6","IPY_MODEL_934693e68d7d4fd29321807791cc1219","IPY_MODEL_8f2a40c472d3478b89425e31aba2ad50"],"layout":"IPY_MODEL_05382371c1024c8394a0380b3d6dfdba"}},"cb7571e81c3342cdbe6fed2d92af893a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd2a3614cccb4b0d80c4245f6994d684":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd405ff754d043c5bd262585aa90bd15":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d510c91c0f814f4cb2eea064fbecd039":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd0fceec185e4599b47ae23faee3035d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2276432c3084b72b910ebf741f99d11","placeholder":"​","style":"IPY_MODEL_f21e83cb77bf4aa7865d73cc1b3473f3","value":"Map (num_proc=4): 100%"}},"df68c92063af4ff59421b9caaaef5855":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_351363cab27a41e881b0b74bf2d1999c","IPY_MODEL_229719041b724dbe97fcfe084b9043ee","IPY_MODEL_869cc8b998a845b489eb68fe6e88ac50"],"layout":"IPY_MODEL_47393e92ea524d2a827cdb9472a7171d"}},"e2eeb063c2e94339a8b8ca6ce7bf67d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f0061ccdc9234fcda904d781685c52c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f21e83cb77bf4aa7865d73cc1b3473f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f93e3d599f8b4edeb796b64068569e8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":4}
